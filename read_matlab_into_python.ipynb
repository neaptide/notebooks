{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .mat < v7.3\n",
    "Try using scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io as spio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haines\\Dropbox\\peach\\dataproc\\data\\level1\\b1\n"
     ]
    }
   ],
   "source": [
    "cd C:/Users/haines/Dropbox/peach/dataproc/data/level1/b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['salin',\n",
       " 'qc',\n",
       " 'press',\n",
       " '__header__',\n",
       " 'gsw_SA',\n",
       " '__globals__',\n",
       " 'platform',\n",
       " 'depth',\n",
       " 'cond',\n",
       " 'dens',\n",
       " 'mtime',\n",
       " 'wtemp',\n",
       " '__version__',\n",
       " 'config']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = spio.loadmat('b1_ctd1_deployall.mat')\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First level keys of dict seem okay, but ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.56976822],\n",
       "       [3.52906765],\n",
       "       [3.53303844],\n",
       "       ...,\n",
       "       [3.58763676],\n",
       "       [3.4466738 ],\n",
       "       [3.21438252]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['depth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested structures are a mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[(array([u'4085'], dtype='<U4'), array([[360]], dtype=uint16), array([u'seconds'], dtype='<U7'), array([[array([u'mtime'], dtype='<U5'),\n",
       "        array([u'days since 0000-01-01T00:00'], dtype='<U27')],\n",
       "       [array([u'wtemp'], dtype='<U5'), array([u'deg C'], dtype='<U5')],\n",
       "       [array([u'press'], dtype='<U5'),\n",
       "        array([u'decibars'], dtype='<U8')],\n",
       "       [array([u'cond'], dtype='<U4'), array([u'S m-1'], dtype='<U5')],\n",
       "       [array([u'salin'], dtype='<U5'), array([u'psu'], dtype='<U3')],\n",
       "       [array([u'depth'], dtype='<U5'), array([u'm'], dtype='<U1')],\n",
       "       [array([u'dens'], dtype='<U4'), array([u'kg m-3'], dtype='<U6')]],\n",
       "      dtype=object))]],\n",
       "      dtype=[('serial_number', 'O'), ('sample_interval', 'O'), ('sample_interval_units', 'O'), ('units', 'O')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key: depth\n",
      "Key: salin\n",
      "Key: dens\n",
      "Key: __header__\n",
      "Key: gsw_SA\n",
      "Key: __globals__\n",
      "Key: platform\n",
      "\tField: id\n",
      "\tField: loc\n",
      "\tField: mean_water_depth\n",
      "\tField: mean_water_depth_units\n",
      "\tField: lat\n",
      "\tField: lon\n",
      "\tField: mvar\n",
      "\tField: start_dn\n",
      "\tField: last_dn\n",
      "Key: qc\n",
      "\tField: rangeTest_cond_tol\n",
      "\tField: rangeTest_press_tol\n",
      "\tField: rangeTest_wtemp_tol\n",
      "Key: cond\n",
      "Key: press\n"
     ]
    }
   ],
   "source": [
    "def print_mat_nested(d, indent=0, nkeys=0):\n",
    "    \"\"\"Pretty print nested structures from .mat files   \n",
    "    Inspired by: `StackOverflow <http://stackoverflow.com/questions/3229419/pretty-printing-nested-dictionaries-in-python>`_\n",
    "    \"\"\"\n",
    "    \n",
    "    # Subset dictionary to limit keys to print.  Only works on first level\n",
    "    if nkeys>0:\n",
    "        d = {k: d[k] for k in d.keys()[:nkeys]}  # Dictionary comprehension: limit to first nkeys keys.\n",
    "\n",
    "    if isinstance(d, dict):\n",
    "        for key, value in d.iteritems():         # iteritems loops through key, value pairs\n",
    "          print '\\t' * indent + 'Key: ' + str(key)\n",
    "          print_mat_nested(value, indent+1)\n",
    "\n",
    "    if isinstance(d,np.ndarray) and d.dtype.names is not None:  # Note: and short-circuits by default\n",
    "        for n in d.dtype.names:    # This means it's a struct, it's bit of a kludge test.\n",
    "            print '\\t' * indent + 'Field: ' + str(n)\n",
    "            print_mat_nested(d[n], indent+1)\n",
    "\n",
    "print_mat_nested(data, nkeys=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .mat >= v7.3\n",
    "Try using pytables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function open_file in module tables.file:\n",
      "\n",
      "open_file(filename, mode='r', title='', root_uep='/', filters=None, **kwargs)\n",
      "    Open a PyTables (or generic HDF5) file and return a File object.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    filename : str\n",
      "        The name of the file (supports environment variable expansion).\n",
      "        It is suggested that file names have any of the .h5, .hdf or\n",
      "        .hdf5 extensions, although this is not mandatory.\n",
      "    mode : str\n",
      "        The mode to open the file. It can be one of the\n",
      "        following:\n",
      "    \n",
      "            * *'r'*: Read-only; no data can be modified.\n",
      "            * *'w'*: Write; a new file is created (an existing file\n",
      "              with the same name would be deleted).\n",
      "            * *'a'*: Append; an existing file is opened for reading and\n",
      "              writing, and if the file does not exist it is created.\n",
      "            * *'r+'*: It is similar to 'a', but the file must already\n",
      "              exist.\n",
      "    \n",
      "    title : str\n",
      "        If the file is to be created, a TITLE string attribute will be\n",
      "        set on the root group with the given value. Otherwise, the\n",
      "        title will be read from disk, and this will not have any effect.\n",
      "    root_uep : str\n",
      "        The root User Entry Point. This is a group in the HDF5 hierarchy\n",
      "        which will be taken as the starting point to create the object\n",
      "        tree. It can be whatever existing group in the file, named by\n",
      "        its HDF5 path. If it does not exist, an HDF5ExtError is issued.\n",
      "        Use this if you do not want to build the *entire* object tree,\n",
      "        but rather only a *subtree* of it.\n",
      "    \n",
      "        .. versionchanged:: 3.0\n",
      "           The *rootUEP* parameter has been renamed into *root_uep*.\n",
      "    \n",
      "    filters : Filters\n",
      "        An instance of the Filters (see :ref:`FiltersClassDescr`) class\n",
      "        that provides information about the desired I/O filters\n",
      "        applicable to the leaves that hang directly from the *root group*,\n",
      "        unless other filter properties are specified for these leaves.\n",
      "        Besides, if you do not specify filter properties for child groups,\n",
      "        they will inherit these ones, which will in turn propagate to\n",
      "        child nodes.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    In addition, it recognizes the (lowercase) names of parameters\n",
      "    present in :file:`tables/parameters.py` as additional keyword\n",
      "    arguments.\n",
      "    See :ref:`parameter_files` for a detailed info on the supported\n",
      "    parameters.\n",
      "    \n",
      "    .. note::\n",
      "    \n",
      "        If you need to deal with a large number of nodes in an\n",
      "        efficient way, please see :ref:`LRUOptim` for more info and\n",
      "        advices about the integrated node cache engine.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tables.open_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
